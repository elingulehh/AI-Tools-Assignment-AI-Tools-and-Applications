{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNqoT1wqzC8dVycd1Nxlz6P"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Minimal Iris -> Decision Tree (with simple preprocessing)\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.impute import SimpleImputer\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n","\n","# 1) Load data as a DataFrame\n","iris = load_iris(as_frame=True)\n","X = iris.data                     # numeric features\n","y = iris.target                   # numeric labels already (0,1,2)\n","target_names = iris.target_names  # ['setosa','versicolor','virginica']\n","\n","\n","# 2) Train/test split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y_enc, test_size=0.2, random_state=42, stratify=y_enc\n",")\n","\n","# 3) Build a simple pipeline: impute missing -> Decision Tree\n","# (Iris has no missing values, but this makes code robust)\n","pipe = Pipeline(steps=[\n","    (\"imputer\", SimpleImputer(strategy=\"median\")),\n","    (\"model\", DecisionTreeClassifier(random_state=42))\n","])\n","\n","# 4) Train\n","pipe.fit(X_train, y_train)\n","\n","# 5) Predict\n","y_pred = pipe.predict(X_test)\n","\n","# 6) Metrics (macro = treats all classes equally)\n","acc  = accuracy_score(y_test, y_pred)\n","prec = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n","rec  = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n","\n","print(f\"Accuracy : {acc:.4f}\")\n","print(f\"Precision (macro): {prec:.4f}\")\n","print(f\"Recall    (macro): {rec:.4f}\")\n","\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, target_names=le.classes_))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F9LzQP5IIcP_","executionInfo":{"status":"ok","timestamp":1760955592784,"user_tz":-180,"elapsed":420,"user":{"displayName":"Nzisa Mwanzia","userId":"06881433516274807884"}},"outputId":"f6ab2c36-e166-4689-a05f-e436a4c474cc"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy : 0.9333\n","Precision (macro): 0.9333\n","Recall    (macro): 0.9333\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        10\n","  versicolor       0.90      0.90      0.90        10\n","   virginica       0.90      0.90      0.90        10\n","\n","    accuracy                           0.93        30\n","   macro avg       0.93      0.93      0.93        30\n","weighted avg       0.93      0.93      0.93        30\n","\n"]}]},{"cell_type":"code","source":["# Iris â‰¥95% with a tuned Decision Tree (simple & clear)\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.impute import SimpleImputer\n","from sklearn.pipeline import Pipeline\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n","\n","# 1) Load data\n","iris = load_iris(as_frame=True)\n","X = iris.data\n","y = iris.target  # already numeric labels (0=setosa, 1=versicolor, 2=virginica)\n","\n","# 2) Train/test split (stratified so class balance is preserved)\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42, stratify=y\n",")\n","\n","# 3) Pipeline: impute (robustness) -> Decision Tree\n","pipe = Pipeline(steps=[\n","    (\"imputer\", SimpleImputer(strategy=\"median\")),\n","    (\"clf\", DecisionTreeClassifier(random_state=0))\n","])\n","\n","# 4) Small hyperparameter grid (kept minimal)\n","param_grid = {\n","    \"clf__criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n","    \"clf__max_depth\": [5, 6, 7, 8, None],\n","    \"clf__min_samples_split\": [2, 4, 6],\n","    \"clf__min_samples_leaf\": [1, 2, 3],\n","}\n","\n","# 5) Grid search with 5-fold CV\n","grid = GridSearchCV(\n","    pipe,\n","    param_grid=param_grid,\n","    cv=5,\n","    n_jobs=-1\n",")\n","grid.fit(X_train, y_train)\n","\n","best_model = grid.best_estimator_\n","print(\"Best params:\", grid.best_params_)\n","\n","# 6) Evaluate on the held-out test set\n","y_pred = best_model.predict(X_test)\n","acc  = accuracy_score(y_test, y_pred)\n","prec = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n","rec  = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n","\n","print(f\"\\nAccuracy : {acc:.4f}\")\n","print(f\"Precision (macro): {prec:.4f}\")\n","print(f\"Recall    (macro): {rec:.4f}\")\n","\n","print(\"\\nClassification report:\")\n","print(classification_report(y_test, y_pred, target_names=iris.target_names))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_JUzb58mm4MR","executionInfo":{"status":"ok","timestamp":1760964195636,"user_tz":-180,"elapsed":4759,"user":{"displayName":"Nzisa Mwanzia","userId":"06881433516274807884"}},"outputId":"c30f2708-569d-46a3-bc3e-122fee7a48ca"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Best params: {'clf__criterion': 'gini', 'clf__max_depth': 5, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2}\n","\n","Accuracy : 0.9667\n","Precision (macro): 0.9697\n","Recall    (macro): 0.9667\n","\n","Classification report:\n","              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        10\n","  versicolor       1.00      0.90      0.95        10\n","   virginica       0.91      1.00      0.95        10\n","\n","    accuracy                           0.97        30\n","   macro avg       0.97      0.97      0.97        30\n","weighted avg       0.97      0.97      0.97        30\n","\n"]}]}]}